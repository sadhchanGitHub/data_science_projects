{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcfb8df8-112c-44e2-ba40-791b2fd19905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows removed: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import hashlib\n",
    "\n",
    "# Load dataset\n",
    "df_final = pd.read_csv(\"../data/processed/recipeNLG_final.csv\").head(50000)\n",
    "\n",
    "# Generate hashes for ingredients and directions\n",
    "def hash_text(text):\n",
    "    return hashlib.md5(text.encode('utf-8')).hexdigest()\n",
    "\n",
    "df_final['ingredients_hash'] = df_final['ingredients'].apply(hash_text)\n",
    "df_final['directions_hash'] = df_final['directions'].apply(hash_text)\n",
    "\n",
    "# Drop duplicates based on hashes\n",
    "df_dedup = df_final.drop_duplicates(subset=['ingredients_hash', 'directions_hash'])\n",
    "\n",
    "# Drop hash columns\n",
    "df_dedup = df_dedup.drop(columns=['ingredients_hash', 'directions_hash'])\n",
    "\n",
    "# Save deduplicated dataset\n",
    "df_dedup.to_csv(\"recipeNLG_deduplicated.csv\", index=False)\n",
    "print(f\"Rows removed: {df_final.shape[0] - df_dedup.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "204113e9-bc11-4c18-94f5-4989f1436803",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Normalize ingredient formatting\n",
    "def normalize_ingredients(ingredients):\n",
    "    ingredients = ingredients.lower().strip()\n",
    "    ingredients = re.sub(r\"\\s+\", \" \", ingredients)  # Normalize spaces\n",
    "    ingredients = re.sub(r\"(\\d+)(\\s*)(tsp|tbsp|cups?)\", r\"\\1 \\3\", ingredients)  # Normalize measurements\n",
    "    return ingredients\n",
    "\n",
    "df_dedup['ingredients'] = df_dedup['ingredients'].apply(normalize_ingredients)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed0100a3-f450-41c5-be3d-f8087c57dd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows removed after normalization: 0\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Normalize text by removing extra spaces, special characters, and standardizing case\n",
    "def normalize_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s,]\", \"\", text)  # Remove special characters\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()  # Normalize spaces\n",
    "    return text\n",
    "\n",
    "# Apply normalization\n",
    "df_final['ingredients'] = df_final['ingredients'].apply(normalize_text)\n",
    "df_final['directions'] = df_final['directions'].apply(normalize_text)\n",
    "\n",
    "# Reapply hashing after normalization\n",
    "df_final['ingredients_hash'] = df_final['ingredients'].apply(hash_text)\n",
    "df_final['directions_hash'] = df_final['directions'].apply(hash_text)\n",
    "\n",
    "# Deduplicate again\n",
    "df_dedup = df_final.drop_duplicates(subset=['ingredients_hash', 'directions_hash'])\n",
    "df_dedup = df_dedup.drop(columns=['ingredients_hash', 'directions_hash'])\n",
    "\n",
    "# Save deduplicated dataset\n",
    "df_dedup.to_csv(\"recipeNLG_deduplicated_normalized.csv\", index=False)\n",
    "print(f\"Rows removed after normalization: {df_final.shape[0] - df_dedup.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a83581a-c67e-43e5-9d69-5d3f8aedc024",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Function to remove near-duplicates\n",
    "def remove_near_duplicates(df, column, threshold=0.9):\n",
    "    vectorizer = CountVectorizer().fit_transform(df[column])\n",
    "    similarity_matrix = cosine_similarity(vectorizer)\n",
    "    to_remove = set()\n",
    "\n",
    "    for i in range(len(similarity_matrix)):\n",
    "        for j in range(i + 1, len(similarity_matrix)):\n",
    "            if similarity_matrix[i, j] > threshold:\n",
    "                to_remove.add(j)\n",
    "\n",
    "    return df.drop(df.index[list(to_remove)])\n",
    "\n",
    "# Apply near-duplicate removal to ingredients and directions\n",
    "df_subset = df_final.sample(n=10000, random_state=42)  # Test with a smaller subset\n",
    "df_subset_dedup = remove_near_duplicates(df_subset, column=\"ingredients\", threshold=0.9)\n",
    "df_subset_dedup = remove_near_duplicates(df_subset_dedup, column=\"directions\", threshold=0.9)\n",
    "\n",
    "print(f\"Rows removed in subset: {df_subset.shape[0] - df_subset_dedup.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "000afe18-2a67-45e7-bb17-be0727540a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows removed after normalization: 0\n"
     ]
    }
   ],
   "source": [
    "# Normalize text\n",
    "def normalize_text(text):\n",
    "    import re\n",
    "    text = text.lower().strip()  # Lowercase and remove leading/trailing spaces\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s,]\", \"\", text)  # Remove special characters\n",
    "    text = re.sub(r\"\\s+\", \" \", text)  # Normalize spaces\n",
    "    return text\n",
    "\n",
    "df_final['ingredients'] = df_final['ingredients'].apply(normalize_text)\n",
    "df_final['directions'] = df_final['directions'].apply(normalize_text)\n",
    "\n",
    "# Reapply hashing after normalization\n",
    "df_final['ingredients_hash'] = df_final['ingredients'].apply(hash_text)\n",
    "df_final['directions_hash'] = df_final['directions'].apply(hash_text)\n",
    "\n",
    "# Drop duplicates again\n",
    "df_dedup = df_final.drop_duplicates(subset=['ingredients_hash', 'directions_hash'])\n",
    "df_dedup = df_dedup.drop(columns=['ingredients_hash', 'directions_hash'])\n",
    "\n",
    "# Save the deduplicated dataset\n",
    "df_dedup.to_csv(\"recipeNLG_deduplicated_normalized.csv\", index=False)\n",
    "print(f\"Rows removed after normalization: {df_final.shape[0] - df_dedup.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db53d137-e41b-439e-89e0-23ea7addd3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          ingredients  \\\n",
      "1   1 small jar chipped beef, cut up, 4 boned chic...   \n",
      "3   1 large whole chicken, 2 10 12 oz cans chicken...   \n",
      "12  chicken wings as many as you need for dinner, ...   \n",
      "31  1 pkg chicken cutlets, 12 c oil, 13 c red vine...   \n",
      "40  3 lb chicken, boiled, 4 medium potatoes, diced...   \n",
      "47  14 c margarine, 14 c chopped onion or as much ...   \n",
      "50  4 chicken breasts, cooked, 1 can cream of chic...   \n",
      "63  1 can cream of mushroom soup, 1 can cream of c...   \n",
      "71  6 c diced potatoes, 12 c chopped onion, 34 c m...   \n",
      "76  chicken parts, 1 can cream of chicken soup, 1 ...   \n",
      "\n",
      "                                           directions  \n",
      "1   place chipped beef on bottom of baking dish, p...  \n",
      "3   boil and debone chicken, put bite size pieces ...  \n",
      "12  clean wings, flour and fry until done, place f...  \n",
      "31                     double recipe for more chicken  \n",
      "40  remove chicken from bone, use the broth, mix t...  \n",
      "47  melt margarine in skillet saute onions and cel...  \n",
      "50  dice chicken, mix all ingredients together, le...  \n",
      "63  mix all ingredients together in baking dish, c...  \n",
      "71  peel and dice potatoes place in bowl of cold, ...  \n",
      "76  add enough liquid to chicken soup and consomme...  \n"
     ]
    }
   ],
   "source": [
    "# Sample rows with similar ingredients for manual inspection\n",
    "sample = df_final[df_final['ingredients'].str.contains(\"chicken\")].head(10)\n",
    "print(sample[['ingredients', 'directions']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4c2985a-a272-4b67-b2c8-67fb0a7af022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0                     title  \\\n",
      "0               0       No-Bake Nut Cookies   \n",
      "1               1     Jewell Ball'S Chicken   \n",
      "2               2               Creamy Corn   \n",
      "3               3             Chicken Funny   \n",
      "4               4      Reeses Cups(Candy)     \n",
      "...           ...                       ...   \n",
      "49995       50007          Texas Fried Okra   \n",
      "49996       50008     Sour Milk Yeast Rolls   \n",
      "49997       50009              Rice Pudding   \n",
      "49998       50010               Green Stuff   \n",
      "49999       50011  Ham And Noodle Casserole   \n",
      "\n",
      "                                             ingredients  \\\n",
      "0      1 c firmly packed brown sugar, 12 c evaporated...   \n",
      "1      1 small jar chipped beef, cut up, 4 boned chic...   \n",
      "2      2 16 oz pkg frozen corn, 1 8 oz pkg cream chee...   \n",
      "3      1 large whole chicken, 2 10 12 oz cans chicken...   \n",
      "4      1 c peanut butter, 34 c graham cracker crumbs,...   \n",
      "...                                                  ...   \n",
      "49995  34 c yellow corn meal, 34 c flour, 1 12 tsp sa...   \n",
      "49996  1 c sour milk do not use buttermilk let milk s...   \n",
      "49997  2 qt milk, 12 c rice, 12 c sugar, lemon rind, ...   \n",
      "49998  pistachio pudding, 1 small can crushed pineapp...   \n",
      "49999  4 c diced cooked ham, 1 large pkg wide noodles...   \n",
      "\n",
      "                                              directions  \\\n",
      "0      in a heavy 2quart saucepan, mix brown sugar, n...   \n",
      "1      place chipped beef on bottom of baking dish, p...   \n",
      "2      in a slow cooker, combine all ingredients cove...   \n",
      "3      boil and debone chicken, put bite size pieces ...   \n",
      "4      combine first four ingredients and press in 13...   \n",
      "...                                                  ...   \n",
      "49995  in a plastic bag,, combine, corn, meal, flour,...   \n",
      "49996  mix sour milk with soda, add sugar, salt and t...   \n",
      "49997  put milk, rice, sugar, lemon rind and salt in ...   \n",
      "49998  combine ingredients until well mixed, pour int...   \n",
      "49999  place cooked ham on bottom of 9 x 13 pan, spre...   \n",
      "\n",
      "                                                   link    source  \\\n",
      "0        www.cookbooks.com/Recipe-Details.aspx?id=44874  Gathered   \n",
      "1       www.cookbooks.com/Recipe-Details.aspx?id=699419  Gathered   \n",
      "2        www.cookbooks.com/Recipe-Details.aspx?id=10570  Gathered   \n",
      "3       www.cookbooks.com/Recipe-Details.aspx?id=897570  Gathered   \n",
      "4       www.cookbooks.com/Recipe-Details.aspx?id=659239  Gathered   \n",
      "...                                                 ...       ...   \n",
      "49995   www.cookbooks.com/Recipe-Details.aspx?id=632822  Gathered   \n",
      "49996  www.cookbooks.com/Recipe-Details.aspx?id=1084591  Gathered   \n",
      "49997   www.cookbooks.com/Recipe-Details.aspx?id=799371  Gathered   \n",
      "49998   www.cookbooks.com/Recipe-Details.aspx?id=756963  Gathered   \n",
      "49999   www.cookbooks.com/Recipe-Details.aspx?id=379278  Gathered   \n",
      "\n",
      "                                                     NER  directions_length  \\\n",
      "0      [\"brown sugar\", \"milk\", \"vanilla\", \"nuts\", \"bu...                357   \n",
      "1      [\"beef\", \"chicken breasts\", \"cream of mushroom...                175   \n",
      "2      [\"frozen corn\", \"cream cheese\", \"butter\", \"gar...                171   \n",
      "3      [\"chicken\", \"chicken gravy\", \"cream of mushroo...                394   \n",
      "4      [\"peanut butter\", \"graham cracker crumbs\", \"bu...                229   \n",
      "...                                                  ...                ...   \n",
      "49995  [\"yellow corn meal\", \"flour\", \"salt\", \"pepper\"...                369   \n",
      "49996  [\"sour milk\", \"soda\", \"sugar\", \"margarine\", \"e...                407   \n",
      "49997  [\"milk\", \"rice\", \"sugar\", \"lemon rind\", \"salt\"...                287   \n",
      "49998  [\"pistachio pudding\", \"pineapple\", \"marshmallo...                 67   \n",
      "49999  [\"wide noodles\", \"Cheddar cheese\", \"cream of m...                247   \n",
      "\n",
      "       ingredients_length                  ingredients_hash  \\\n",
      "0                     187  29de8e28f98d875f070951409fae57e5   \n",
      "1                     118  0eced6b00ce3540dd2bd4d96f2f7444a   \n",
      "2                     155  d4e05ea3099e2c2902d8e10b7a8aa76d   \n",
      "3                     168  a956acee2153826b325644136ca0251c   \n",
      "4                     143  b209d177f5a93aaa16c3db5904c9aebd   \n",
      "...                   ...                               ...   \n",
      "49995                 158  1cc4b43ae4cb8b3ac0ddb41ec8ccbe8e   \n",
      "49996                 234  f451b4100298d77fcdc9a136d339477b   \n",
      "49997                 120  5f5bd9bd5d5719b5a6059c1c05c0682b   \n",
      "49998                 106  52cb90b7c3ba9e36c2fc02c3864b2a58   \n",
      "49999                 140  a849ae1643979f03a3e610eada49fa1b   \n",
      "\n",
      "                        directions_hash  \n",
      "0      429af62748cda7a3d1dff0496aec7476  \n",
      "1      56ce9c61d05b3f95f1ad412559397448  \n",
      "2      d4300f6753f9afcea6ddee342107d0ff  \n",
      "3      d740c602b78e7b324120a249585cd046  \n",
      "4      da119db3cf3ba2962d829979b2ba30f8  \n",
      "...                                 ...  \n",
      "49995  78b2ff9bb48f3a0061f986227bcbe773  \n",
      "49996  98ed2ef9979f9324ff3b2b4a542729b5  \n",
      "49997  efec61c18c4c5fc611514e230965edec  \n",
      "49998  e10a8fa3251a68893ae4d3503c29d02a  \n",
      "49999  81e645e4e3c828e4cc19e569a21965b8  \n",
      "\n",
      "[50000 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "vague_rows = df_final[\n",
    "    df_final[\"ingredients\"].str.contains(\"etc|some|as needed\", na=False, case=False) |\n",
    "    df_final[\"directions\"].str.len() < 10  # Very short directions\n",
    "]\n",
    "print(vague_rows)\n",
    "\n",
    "## The vague_rows output you shared indicates that no rows matched the criteria for vague ingredients \n",
    "## or excessively short directions in your dataset. This suggests that the data quality in terms of \n",
    "## ingredient and direction lengths is reasonable for generating recipes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc05bd5b-ec4f-45a2-a782-078be3c880d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (textanalytics_env)",
   "language": "python",
   "name": "textanalytics_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
