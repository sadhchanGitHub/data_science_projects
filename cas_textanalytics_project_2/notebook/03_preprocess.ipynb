{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84d7f977-f75b-4db1-a61b-a0c83fa2741d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Time: 2025-01-01 17:16:07.675393\n",
      "End Time: 2025-01-01 17:16:52.019125\n",
      "Processing Time: 0:00:44.343732\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import spacy\n",
    "\n",
    "# Load spaCy's English tokenizer with optimizations\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\", \"parser\"])  # Disable unnecessary components\n",
    "\n",
    "# Define an optimized cleaning function using spaCy\n",
    "def clean_text_spacy_optimized(text):\n",
    "    doc = nlp(text.lower())  # Lowercase conversion before tokenizing\n",
    "    tokens = [token.text for token in doc if not token.is_stop and token.is_alpha]  # Filter stopwords and non-alphabetic tokens\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Example data\n",
    "mock_data = [\"This is a sample review! Amazing food, great service.\"] * 1000\n",
    "\n",
    "# Start timing\n",
    "start_time = datetime.now()\n",
    "\n",
    "# Apply cleaning to the dataset\n",
    "cleaned_reviews = [clean_text_spacy_optimized(review) for review in mock_data]\n",
    "\n",
    "# End timing\n",
    "end_time = datetime.now()\n",
    "\n",
    "# Print timing information\n",
    "print(f\"Start Time: {start_time}\")\n",
    "print(f\"End Time: {end_time}\")\n",
    "print(f\"Processing Time: {end_time - start_time}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d2cc138-1867-4ea5-a2e5-f2405e379cf5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Time: 2025-01-01 18:23:41.324082\n",
      "End Time: 2025-01-01 19:20:30.406917\n",
      "Processing Time: 0:56:49.082835\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import dask.dataframe as dd\n",
    "import spacy\n",
    "\n",
    "# Load spaCy's English tokenizer with optimizations\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\", \"parser\"])  # Disable unnecessary components\n",
    "\n",
    "# Define an optimized cleaning function using spaCy\n",
    "def clean_text_spacy_optimized(text):\n",
    "    doc = nlp(text.lower())  # Lowercase conversion before tokenizing\n",
    "    tokens = [token.text for token in doc if not token.is_stop and token.is_alpha]  # Filter stopwords and non-alphabetic tokens\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Load dataset using Dask\n",
    "ddf = dd.read_csv(\"../data/New_York_reviews_cleaned.csv\")  # Replace with your dataset file path\n",
    "\n",
    "# Start timing\n",
    "start_time = datetime.now()\n",
    "\n",
    "# Apply the cleaning function using Dask's map\n",
    "ddf['cleaned_review'] = ddf['review_full'].map(clean_text_spacy_optimized, meta=('review_full', 'str'))\n",
    "\n",
    "# Execute the computation and convert back to Pandas\n",
    "df_cleaned = ddf.compute()\n",
    "\n",
    "# End timing\n",
    "end_time = datetime.now()\n",
    "\n",
    "# Print timing information\n",
    "print(f\"Start Time: {start_time}\")\n",
    "print(f\"End Time: {end_time}\")\n",
    "print(f\"Processing Time: {end_time - start_time}\")\n",
    "\n",
    "# Save the cleaned dataset\n",
    "df_cleaned.to_csv(\"../data/New_York_reviews_cleaned_with_spacy.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0a3ea2e-b9cd-40d6-8d54-bdd826f183e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_cleaned' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdf_cleaned\u001b[49m[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreview_full\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcleaned_review\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mhead())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_cleaned' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81e88656-0b6a-4bd4-874e-d9198ae78c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_test = pd.read_csv('../data/New_York_reviews_cleaned_with_spacy.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca977147-6e8a-416a-a9b3-69cd2a470847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         review_full  \\\n",
      "0  My wife and I have been eating dinner frequent...   \n",
      "1  Came with family for Labor Day weekend brunch ...   \n",
      "2  Food was mediocre at best. The lamb chops are ...   \n",
      "3  My co-workers were volunteering at a foodbank ...   \n",
      "4  Lido is an intimate boutique style restaurant....   \n",
      "\n",
      "                                      cleaned_review  \n",
      "0  wife eating dinner frequently lido virtually d...  \n",
      "1  came family labor day weekend brunch daughter ...  \n",
      "2  food mediocre best lamb chops image feature we...  \n",
      "3  co workers volunteering foodbank corner came l...  \n",
      "4  lido intimate boutique style restaurant servin...  \n"
     ]
    }
   ],
   "source": [
    "print(df_test[['review_full', 'cleaned_review']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "647261e2-9ec3-4f5a-b292-120a346eeeb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['restaurant_name', 'rating_review', 'sample', 'review_id',\n",
      "       'title_review', 'review_preview', 'review_full', 'date', 'city',\n",
      "       'url_restaurant', 'author_id', 'review_length', 'cleaned_review'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_test.columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1bfb63d6-12d8-4f76-b0ff-63d6c9e8d6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  restaurant_name  rating_review    sample         review_id  \\\n",
      "0            Lido              5  Positive  review_773559838   \n",
      "1            Lido              4  Positive  review_769429529   \n",
      "2            Lido              1  Negative  review_745700258   \n",
      "3            Lido              5  Positive  review_728859349   \n",
      "4            Lido              5  Positive  review_728429643   \n",
      "\n",
      "              title_review                                     review_preview  \\\n",
      "0          A Regular Treat  My wife and I have been eating dinner frequent...   \n",
      "1  Good neighborhood spot!  Came with family for Labor Day weekend brunch ...   \n",
      "2            Disappointing  Food was mediocre at best.  The lamb chops are...   \n",
      "3    What a find in Harlem  My co-workers were volunteering at a foodbank ...   \n",
      "4                    Lunch  Lido is an intimate boutique style restaurant....   \n",
      "\n",
      "                                         review_full               date  \\\n",
      "0  My wife and I have been eating dinner frequent...    October 8, 2020   \n",
      "1  Came with family for Labor Day weekend brunch ...  September 8, 2020   \n",
      "2  Food was mediocre at best. The lamb chops are ...  February 17, 2020   \n",
      "3  My co-workers were volunteering at a foodbank ...  November 25, 2019   \n",
      "4  Lido is an intimate boutique style restaurant....  November 23, 2019   \n",
      "\n",
      "                     city                                     url_restaurant  \\\n",
      "0  New_York_City_New_York  https://www.tripadvisor.com/Restaurant_Review-...   \n",
      "1  New_York_City_New_York  https://www.tripadvisor.com/Restaurant_Review-...   \n",
      "2  New_York_City_New_York  https://www.tripadvisor.com/Restaurant_Review-...   \n",
      "3  New_York_City_New_York  https://www.tripadvisor.com/Restaurant_Review-...   \n",
      "4  New_York_City_New_York  https://www.tripadvisor.com/Restaurant_Review-...   \n",
      "\n",
      "  author_id  review_length                                     cleaned_review  \n",
      "0     UID_0            534  wife eating dinner frequently lido virtually d...  \n",
      "1     UID_1            390  came family labor day weekend brunch daughter ...  \n",
      "2     UID_2            309  food mediocre best lamb chops image feature we...  \n",
      "3     UID_3            312  co workers volunteering foodbank corner came l...  \n",
      "4     UID_4            200  lido intimate boutique style restaurant servin...  \n"
     ]
    }
   ],
   "source": [
    "print(df_test.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a48f3bd3-ee83-4926-8d50-beb6ea31875d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df_test['cleaned_review'].isnull().sum())  # Count missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03569e7a-c8e6-47fd-802f-d55163ff32db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['cleaned_review'] = df_test['cleaned_review'].fillna('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "437c99a0-c709-4203-87ff-61038e5fed41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['cleaned_review'] = df_test['cleaned_review'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6c93afc-be82-4e16-a686-9df73dd30db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv(\"../data/New_York_reviews_cleaned_with_spacy.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9570f992-29a2-4725-862c-a8b6979796b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(509612, 13)\n"
     ]
    }
   ],
   "source": [
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "251e1953-32ae-4e59-bee8-ad83af3f8532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "object\n"
     ]
    }
   ],
   "source": [
    "print(df_test['cleaned_review'].isnull().sum())  # Check for NaN values\n",
    "print(df_test['cleaned_review'].dtype)          # Check the column data type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca2f948f-4701-4e47-9904-45356430dd09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Count empty strings\n",
    "print((df_test['cleaned_review'] == \"\").sum())  # Count exact empty strings\n",
    "\n",
    "# Count whitespace-only strings\n",
    "print((df_test['cleaned_review'].str.isspace()).sum())  # Count strings with only spaces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eee013ba-3583-4d60-bf55-0480f36b6986",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Rows with Empty Strings\n",
    "df_test['cleaned_review'] = df_test['cleaned_review'].replace(\"\", \"[empty_review]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405b696d-2098-40c8-8dfb-9bc4e185e8ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (textanalytics_env)",
   "language": "python",
   "name": "textanalytics_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
